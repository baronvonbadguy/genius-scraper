{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "#### General notes and inspiration\n",
    "- [matching rhymes from hamilton](http://graphics.wsj.com/hamilton-methodology/)\n",
    "    - [details](https://journalism.stanford.edu/cj2016/files/Writing%20an%20Algorithm%20To%20Analyze%20and%20Visualize%20Lyrics%20From%20the%20Musical%20Hamilton.pdf)\n",
    "- [general notes on rhyming](http://mtosmt.org/issues/mto.17.23.4/mto.17.23.4.komaniecki.html)\n",
    "  - Rhyming groups are set in similar metrical locations.\n",
    "  - Rhyming groups are set to similar rhythmic figures.\n",
    "  - Rhyming groups are emphasized or articulated in similar ways.\n",
    "  \n",
    "#### Finding Rhymes\n",
    "- [applying BLOSUM to phoneme combinations](https://pdfs.semanticscholar.org/8b66/ea2b1fdc0d7df782545886930ddac0daa1de.pdf)\n",
    "- [converting phonemes to syllables](http://www.anthology.aclweb.org/N/N09/N09-1035.pdf)\n",
    "- [phonetic similarity metrics](https://homes.cs.washington.edu/~bhixon/papers/phonemic_similarity_metrics_Interspeech_2011.pdf)\n",
    "\n",
    "#### Substitutions\n",
    "- [constonant misidentification](http://www.ebire.org/hcnlab/papers/WoodsJASA2010.pdf)\n",
    "- [ARPABET to IPA](https://www.wikiwand.com/en/ARPABET)\n",
    "- [B-Rhymes](http://www.b-rhymes.com/faq/)\n",
    "\n",
    "#### Syllables\n",
    "- [sylabification code](https://raw.githubusercontent.com/vgautam/arpabet-syllabifier/master/syllabifyARPA.py)\n",
    "- [sonority scale](https://www.wikiwand.com/en/Sonority_hierarchy)\n",
    "    - [more sonority scale](https://www.wikiwand.com/en/Sonority_hierarchy)\n",
    "    - [arpabet sonority mapping](https://ipfs.io/ipfs/QmXoypizjW3WknFiJnKLwHCnL72vedxjQkDDP1mXWo6uco/wiki/Arpabet.html)\n",
    "    - [sonority information](http://people.cs.uchicago.edu/~niyogi/papersps/lsrpaper.pdf)\n",
    "- [general ideas on syllables](http://sitr.us/2007/09/24/anatomy-of-a-syllable.html)\n",
    "- [rules for syllabification](http://alias-i.com/lingpipe/demos/tutorial/hyphenation/read-me.html)\n",
    "- [align graphenes to phonemes](http://www.aclweb.org/anthology/P10-1080)\n",
    "    - [code](https://github.com/letter-to-phoneme/m2m-aligner)\n",
    "- [syllabification of phonemes](http://www.anthology.aclweb.org/N/N09/N09-1035.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eminem-and-dj-buttafingaz.mpk\r\n",
      "Eminem-ft-logic-joyner-lucas-nitin-randhawa-remix.mpk\r\n",
      "Eminem.mpk\r\n",
      "Eminem-x-proof.mpk\r\n"
     ]
    }
   ],
   "source": [
    "!ls lyrics_consolidated/ | grep Eminem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm words-missing-from-cmu.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ahhh': 'AE1 HH',\n",
       " 'gnac': 'G AE1 N AH0 K',\n",
       " 'titties': 'T IH1 T IY0 Z',\n",
       " 'Pharoahe': 'F AA0 R OW1',\n",
       " 'Monch': 'M AA1 N CH',\n",
       " \"style's\": 'S T AY1 L Z',\n",
       " 'Girlies': 'G IH1 R L IY0 Z',\n",
       " 'BMs': 'B AE1 M Z',\n",
       " '12pm': 'T W EH1 L V EH2 P AH0 M',\n",
       " 'eses': 'EH1 S AH0 Z',\n",
       " 'Rollies': 'R AA1 L IY0 Z',\n",
       " 'Jeru': 'JH EH1 R UW0',\n",
       " 'shrooms': 'SH R UW1 M Z',\n",
       " 'Coka': 'K OW1 K AH0',\n",
       " '___': '',\n",
       " '____': '',\n",
       " 'Teleportation': 'T EH2 L AH0 P ER0 T EY1 SH AH0 N',\n",
       " 'realer': 'R IY1 L ER0',\n",
       " 'Illuminati': 'IH0 L UW2 M AH0 N EY1 T IY0',\n",
       " 'guillotines': 'G IH1 L AH0 T AY2 N Z',\n",
       " 'decapitating': 'D IH0 K AE1 P AH0 T EY2 T IH0 NG',\n",
       " 'can’t': 'K AE1 N T',\n",
       " 'I’m': 'IH1 M',\n",
       " 'Mongolians': 'M AH0 NG G OW1 L IY0 AH0 N Z',\n",
       " 'it’s': 'IH1 T S',\n",
       " 'humanity’s': 'HH Y UW0 M AE1 N AH0 T IY0 Z',\n",
       " 'don’t': 'D AA1 N T',\n",
       " 'should’ve': 'SH AW1 L D Z',\n",
       " 'meds': 'M EH1 D Z',\n",
       " 'Lucifer’s': 'L UW1 S AH0 F ER0 Z',\n",
       " 'that’s': 'TH AE1 T S',\n",
       " 'Ain’t': 'EY1 N T',\n",
       " 'Millionare': 'M IH1 L IY0 AH0 N EH2 R',\n",
       " 'vansens': 'V AE1 N S AH0 N Z',\n",
       " 'niggas': 'N IH1 G AH0 Z',\n",
       " 'abulance': 'AH0 B Y UW1 L AH0 N S',\n",
       " 'Manhattens': 'M AH0 N HH AE1 T AH0 N Z',\n",
       " '2006': 'T UW1   TH AW1 Z AH0 N D   S IH1 K S',\n",
       " 'whatchu': 'W AE1 CH UW0',\n",
       " 'Corolas': 'K ER0 OW1 L AH0 S',\n",
       " 'playboys': 'P L EY1 B OY2 Z',\n",
       " '4th': 'F AO1 R TH',\n",
       " 'JanSport': 'JH AE1 N S P AO2 R T',\n",
       " 'religous': 'R EH1 L IH0 G AH0 S',\n",
       " 'terrorismSeem': 'T EH1 R ER0 IH0 S M Z AH0 M',\n",
       " \"Jesus'fragile\": 'JH EH1 S AH0 S F R EY1 JH AH0 L',\n",
       " '6': 'S IH1 K S',\n",
       " 'blam': 'B L AE1 M',\n",
       " '{Saddam': 'S AA1 D AH0 M',\n",
       " 'Iraq}': 'IH0 R AA1 K',\n",
       " '{Retaliation}': 'R IY0 T AE2 L IY0 EY1 SH AH0 N',\n",
       " '{President': 'P R EH1 Z AH0 D EH2 N T',\n",
       " 'Bush}': 'B UH1 SH',\n",
       " '{48': 'F AO1 R T IY0 V AY2 T',\n",
       " 'hours}': 'AW1 ER0 Z',\n",
       " '{Give': 'G IH1 V',\n",
       " 'power}': 'P AW1 ER0',\n",
       " '{Brink': 'B R IH1 NG K',\n",
       " '2': 'T UW1',\n",
       " '{His': 'HH IH1 Z',\n",
       " 'over}': 'OW1 V ER0',\n",
       " '{Homeland': 'HH OW1 M L AE2 N D',\n",
       " 'Security}': 'S IH0 K Y UH1 R AH0 T IY0',\n",
       " \"{Nation's\": 'N EY1 SH AH0 N Z',\n",
       " 'level}': 'L EH1 V AH0 L',\n",
       " '{High': 'HH AY1',\n",
       " 'alert}': 'AH0 L ER1 T',\n",
       " '{The': 'DH AH0',\n",
       " 'world}': 'W ER1 L D',\n",
       " \"nigga's\": 'N IH1 G AH0 Z',\n",
       " '{Coming': 'K AH1 M IH0 NG',\n",
       " 'bring}': 'B R IH1 NG',\n",
       " '{Military}': 'M IH1 L AH0 T EH2 R IY0',\n",
       " '{Weapons': 'W EH1 P AH0 N Z',\n",
       " 'destruction}': 'D IH0 S T R AH1 K SH AH0 N',\n",
       " '{Protect': 'P R AH0 T EH1 K T',\n",
       " 'country}': 'K AH1 N T R IY0',\n",
       " '{And': 'AH0 N D',\n",
       " 'intimidated}': 'IH0 N T IH1 M IH0 D EY2 T IH0 D',\n",
       " '{By': 'B AY1',\n",
       " 'thugs}': 'TH AH1 G Z',\n",
       " 'reappearing': 'R IY0 AH0 P IY1 R IH0 NG',\n",
       " \"shark's\": 'SH AA1 R K S',\n",
       " '45': 'F AO1 R T IY0 F AY2 V',\n",
       " 'peuto': 'P UW1 T OW0',\n",
       " 'stepdad': 'S T EH1 P D AH0 D',\n",
       " 'spick': 'S P IH1 K',\n",
       " 'próximo': 'P R AA1 K S AH0 M OW0',\n",
       " 'planeta': 'P L AA0 N EH1 T AH0',\n",
       " 'despedaça': 'D IH0 S P EH1 D AH0 K AH0',\n",
       " 'bata': 'B AA1 T AH0',\n",
       " 'dê': 'D IY1',\n",
       " 'dez': 'D EH1 Z',\n",
       " 'tapa': 'T AA1 P AH0',\n",
       " 'Não': 'N AA1 OW0',\n",
       " 'peça': 'P EH1 K AH0',\n",
       " 'distância': 'D IH0 S T AE1 N S IY0 AH0',\n",
       " 'Nem': 'N EH1 M',\n",
       " 'despeça': 'D IH0 S P IY1 K AH0',\n",
       " 'minha': 'M IH1 N HH AH0',\n",
       " 'gata': 'G AE1 T AH0',\n",
       " 'inútil': 'IH0 N UW1 T AH0 L',\n",
       " 'sou': 'S UW1',\n",
       " 'sei': 'S IY1',\n",
       " 'ataca': 'AH0 T AA1 K AH0',\n",
       " 'taca': 'T AE1 K AH0',\n",
       " 'faca': 'F AE1 K AH0',\n",
       " 'Trata': 'T R AA1 T AH0',\n",
       " 'matar': 'M AE1 T ER0',\n",
       " 'É': 'IY1',\n",
       " 'preço': 'P R EH1 K OW0',\n",
       " 'é': 'IY1',\n",
       " 'só': 'S OW1',\n",
       " 'terço': 'T ER1 K OW0',\n",
       " 'Mereço': 'M EH0 R IY1 K OW0',\n",
       " 'muito': 'M UW1 T OW0',\n",
       " 'raiva': 'R EY1 V AH0',\n",
       " 'desprezo': 'D IH0 S P R IY1 Z OW0',\n",
       " 'mereço': 'M EH0 R IY1 K OW0',\n",
       " 'fim': 'F IH1 M',\n",
       " 'trate': 'T R EY1 T',\n",
       " 'assim': 'AE1 S IH0 M',\n",
       " 'Entendo': 'EH0 N T EH1 N D OW0',\n",
       " 'aprendo': 'AH0 P R EH1 N D OW0',\n",
       " 'enfim': 'EH1 N F IH0 M',\n",
       " 'demais': 'D IH0 M EY1 Z',\n",
       " 'Acaba': 'AH0 K AA1 B AH0',\n",
       " 'ruim': 'R UW1 AH0 M',\n",
       " 'Hoje': 'HH OW1 Y UW0',\n",
       " 'não': 'N AA1 OW0',\n",
       " 'tem': 'T EH1 M',\n",
       " 'sorrisos': 'S AO1 R IH0 S AH0 Z',\n",
       " 'terão': 'T EH1 R AH0',\n",
       " 'Terão': 'T EH1 R AH0',\n",
       " 'lamentos': 'L AH0 M EH1 N T OW0 Z',\n",
       " 'afins': 'AE1 F IH0 N Z',\n",
       " 'depressão': 'D IH0 P R EH1 SH AH0',\n",
       " 'desse': 'D EH1 S',\n",
       " 'Fui': 'F Y UW1 IY0',\n",
       " 'Relembra': 'R IH0 L EH1 M B R AH0',\n",
       " 'meus': 'M UW1 Z',\n",
       " 'olhos': 'OW1 L HH OW0 Z',\n",
       " 'azuis': 'AH0 Z UW1 IH0 S',\n",
       " 'brilhavam': 'B R IH1 L HH AH0 V AH0 M',\n",
       " 'esmeraldas': 'EH1 S M ER0 AH0 L D AH0 Z',\n",
       " 'safiras': 'S AH0 F IH1 R AH0 Z',\n",
       " 'céu': 'S IY1',\n",
       " 'estrelado': 'EH0 S T R AH0 L AA1 D OW0',\n",
       " 'possível': 'P AA1 S IH0 V AH0 L',\n",
       " 'Refletindo': 'R EH2 F AH0 L T IH1 N D OW0',\n",
       " 'oceano': 'OW0 S IY1 N OW0',\n",
       " 'seu': 'S UW1',\n",
       " 'olhar': 'OW1 L HH AA2 R',\n",
       " 'trazia': 'T R AA1 Z IY0 AH0',\n",
       " 'Onde': 'AA1 N D',\n",
       " 'já': 'Y AA1',\n",
       " 'impossível': 'IH0 M P AA1 S IH0 V AH0 L',\n",
       " 'suportar': 'S UW1 P ER0 T AA2 R',\n",
       " 'queria': 'K W EH1 R IY0 AH0',\n",
       " 'Beyoncé': 'B AY1 AH0 N S',\n",
       " 'Você': 'V OW1 S',\n",
       " 'quis': 'K W IH1 Z',\n",
       " 'algo': 'AE1 L G OW0',\n",
       " 'instantes': 'IH0 N S T AE1 N T S',\n",
       " 'você': 'V OW1 S',\n",
       " 'nunca': 'N AH1 NG K AH0',\n",
       " 'pedi': 'P IY1 D IY0',\n",
       " 'Só': 'S OW1',\n",
       " 'ser': 'S ER1',\n",
       " 'sua': 'S UW1 AH0',\n",
       " 'errei': 'ER0 IY1 IY0',\n",
       " 'joguei': 'JH OW0 G IY1',\n",
       " 'Cê': 'S IY1',\n",
       " 'quer': 'K W ER1',\n",
       " 'pra': 'P R EY1',\n",
       " 'trás': 'T R AE1 S',\n",
       " 'devora': 'D IH0 V AO1 R AH0',\n",
       " 'olhares': 'OW0 L HH EH1 R EH0 S',\n",
       " 'dispensa': 'D IH0 S P EH1 N S AH0',\n",
       " 'dizeres': 'D AY1 Z ER0 Z',\n",
       " 'Repensa': 'R IH0 P EH1 N S AH0',\n",
       " 'sobre': 'S OW1 B R IY0',\n",
       " 'ir': 'ER1',\n",
       " 'embora': 'EH0 M B AO1 R AH0',\n",
       " 'Lembra': 'L EH1 M B R AH0',\n",
       " 'nossos': 'N AA1 S OW0 Z',\n",
       " 'prazeres': 'P R EY1 Z ER0 Z',\n",
       " 'Tenta': 'T EH1 N T AH0',\n",
       " 'pensar': 'P EH1 N S ER0',\n",
       " 'amenizo': 'AA0 M EH0 N IY1 Z OW0',\n",
       " 'suas': 'S UW1 AH0 Z',\n",
       " 'dores': 'D AO1 R Z',\n",
       " 'dá': 'D AA1',\n",
       " 'sorriso': 'S AO0 R IY1 S OW0',\n",
       " 'chora': 'CH AO1 R AH0',\n",
       " 'Traga': 'T R AA1 G AH0',\n",
       " 'minhas': 'M IH1 N HH AH0 Z',\n",
       " 'Fodam': 'F OW1 D AH0 M',\n",
       " 'goles': 'G OW1 L Z',\n",
       " 'satisfazem': 'S AE1 T IH0 S F EY2 Z AH0 M',\n",
       " 'melhor': 'M EH1 L HH ER0',\n",
       " 'porra': 'P AO1 R AH0',\n",
       " 'Isso': 'IH1 S OW0',\n",
       " 'deixa': 'D IY1 K S AH0',\n",
       " 'tudo': 'T UW1 D OW0',\n",
       " 'pior': 'P AY1 ER0',\n",
       " 'Quando': 'K W AA1 N D OW0',\n",
       " 'considero': 'K AA0 N S IY0 D EH1 R OW0',\n",
       " 'Vem': 'V EH1 M',\n",
       " 'sensação': 'S EH0 N S AA1 K AH0',\n",
       " 'dó': 'D UW1',\n",
       " 'conforto': 'K AH0 N F AO1 R T OW0',\n",
       " 'mesmo': 'M EH1 S M OW0',\n",
       " 'morto': 'M AO1 R T OW0',\n",
       " 'sentir': 'S EH1 N T ER0',\n",
       " 'tão': 'T AW1',\n",
       " 'solidão': 'S OW0 L IY1 D OW0',\n",
       " 'meu': 'M UW1',\n",
       " 'Meu': 'M UW1'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from os import path as osp\n",
    "missing_words_file = 'words-missing-from-cmu.json'\n",
    "if osp.isfile(missing_words_file):\n",
    "    with open(missing_words_file, 'r') as wf:\n",
    "        WORDS_MISSING_FROM_CMU = json.load(wf)\n",
    "else:\n",
    "    WORDS_MISSING_FROM_CMU = {}\n",
    "WORDS_MISSING_FROM_CMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import msgpack\n",
    "from random import choice\n",
    "from pprint import pprint as pp\n",
    "\n",
    "lyric = ''\n",
    "with open('lyrics_consolidated/Pharoahe-monch.mpk', 'rb') as lyric:\n",
    "    corp = msgpack.unpack(lyric, encoding='utf-8')\n",
    "    lyric = corp['Pharoahe-monch-simon-says-lyrics']['lyrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def process_line(line):\n",
    "    words = []\n",
    "    # remove adlibs\n",
    "    line = re.sub('\\(.+?\\)', '', line)\n",
    "    # split words delimited by either spaces or commas\n",
    "    for word in re.split('[ ,]', line):\n",
    "        # strip out lots of characters we don't want for our\n",
    "        # word analysis, but keep apostrophies\n",
    "        stripped = re.sub(r\"(^'|'$|[;\\?\\!\\n \\t\\\"\\:]|\\.+|\\…)+\", '', word)\n",
    "        # convert a hyphenated word into multiple words\n",
    "        words += re.split(r\"[-–—]\", stripped)\n",
    "    no_blanks = list(filter(None, words))\n",
    "    return no_blanks\n",
    "\n",
    "def clean_headers(lyrics):\n",
    "    processed = []\n",
    "    for line in lyrics:\n",
    "        # filter out song block headers that can span multiple lines\n",
    "        opened = re.search('^\\[', line)\n",
    "        closed = re.search('\\]$', line)\n",
    "        if opened:\n",
    "            bracket_open = True\n",
    "        if bracket_open:\n",
    "            if closed:\n",
    "                bracket_open = False\n",
    "            continue\n",
    "        line = process_line(line)\n",
    "        if line:\n",
    "            processed.append(line)\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import g2p_en as g2p\n",
    "import pronouncing\n",
    "\n",
    "def get_phones(text, stress=True):\n",
    "    phoned = []\n",
    "    with g2p.Session():\n",
    "        for line in text:\n",
    "            phoned_line = []\n",
    "            for word in line:\n",
    "                phones = pronouncing.phones_for_word(word)        \n",
    "                # lots of words in genius are listed as being\n",
    "                # pronounced as 'in' instead of the formal\n",
    "                # 'ing' spelling that is in the cmu data\n",
    "                # and needs modification to correct\n",
    "                if not phones and re.search('in\\'?$', word):\n",
    "                    subbed = re.sub(r'in\\'?', 'ing', word)\n",
    "                    with_g = pronouncing.phones_for_word(subbed)\n",
    "                    if with_g:\n",
    "                        # convert the 'ng' phenomes to 'n'\n",
    "                        without_g = re.sub(r'(?<=IH\\d) (NG)$', ' N', with_g[0])\n",
    "                        phones = without_g\n",
    "                # some words start with an apostraphy and might not\n",
    "                # be listed in the cmu as such\n",
    "                elif not phones and re.search(\"^['`‘]\", word):\n",
    "                    without_apo = pronouncing.phones_for_word(word[1:])\n",
    "                    if without_apo:\n",
    "                        phones = without_apo[0]\n",
    "                # fallback to use slower g2p\n",
    "                elif not phones:\n",
    "                    phones_cached = WORDS_MISSING_FROM_CMU.get(word)\n",
    "                    if not phones_cached:\n",
    "                        phones = ' '.join(g2p.g2p(word))\n",
    "                        WORDS_MISSING_FROM_CMU[word] = phones\n",
    "                    else:\n",
    "                        phones = phones_cached\n",
    "                # we don't need nested lists\n",
    "                else:\n",
    "                    phones = phones[0]\n",
    "                # the numbers after a phenome are useful for determining\n",
    "                # stresses and syllables within words, but aren't that\n",
    "                # useful for comparing sounds themselves (rhymes)\n",
    "                if not stress and phones:\n",
    "                    phones = re.sub('\\d*', '', phones)\n",
    "                if phones:\n",
    "                    phoned_line.append(phones)\n",
    "            phoned.append(phoned_line)\n",
    "    with open(missing_words_file, 'w') as wf:\n",
    "        json.dump(WORDS_MISSING_FROM_CMU, wf)\n",
    "    return phoned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arp_to_ipa_vowels = {\n",
    "#     'AA': 'ɑ', 'AE': 'æ', 'AH': 'ʌ', 'AO': 'ɔ', 'AW': 'aʊ', \n",
    "#     'AX': 'ə', 'AY': 'aɪ', 'EH': 'ɛ', 'ER': 'ɝ', 'EY': 'eɪ', \n",
    "#     'IH': 'ɪ', 'IX': 'ɨ', 'IY': 'i', 'UX': 'ʉ',\n",
    "#     'OW': 'oʊ','OY': 'ɔɪ','UH': 'ʊ','UW': 'u',}\n",
    "# arp_to_ipa_constonants = {\n",
    "#     'CH': 'tʃ','D': 'd','DH': 'ð','DX': 'ɾ','EL': 'l̩',\n",
    "#     'EM': 'm̩','EN': 'n̩','F': 'f','G': 'ɡ','HH': 'h',\n",
    "#     'JH': 'dʒ','K': 'k','L': 'l','M': 'm','N': 'n',\n",
    "#     'NX': 'ŋ','P': 'p','Q': 'ʔ','R': 'ɹ','S': 's',\n",
    "#     'SH': 'ʃ','T': 't','TH': 'θ','V': 'v','W': 'w',\n",
    "#     'WH': 'ʍ','Y': 'j','Z': 'z','ZH': 'ʒ', 'B': 'b',\n",
    "# }\n",
    "# arp_to_ipa = {**arp_to_ipa_vowels, **arp_to_ipa_constonants}\n",
    "sonority_scale = {\n",
    "# vowels\n",
    "'IY': 4, 'IH': 4, 'EH': 4, 'EY': 4, 'AE': 4, 'AA': 4, 'AW': 4, \n",
    "'AY': 4, 'AH': 4, 'AO': 4, 'OY': 4, 'OW': 4, 'UH': 4, 'UW': 4, \n",
    "'UX': 4, 'ER': 4, 'AX': 4, 'IX': 4, 'AXR': 4, 'AX-H': 4,\n",
    "# glides\n",
    "'Y': 3, 'W': 3, 'Q': 3, \n",
    "# liquids\n",
    "'L': 2, 'EL': 2, 'R': 2, 'DX': 2, 'NX': 2,\n",
    "# nasals\n",
    "'M': 1, 'EM': 1, 'N': 1, 'EN': 1, 'NG': 1, 'ENG': 1,\n",
    "## obstruents\n",
    "# stops/plosives\n",
    "'P': 0, 'B': 0, 'T': 0, 'D': 0, 'K': 0, 'G': 0,\n",
    "# affricates\n",
    "'CH': 0, 'JH': 0,\n",
    "# fricatives\n",
    "'F': 0,'V': 0,'TH': 0,'DH': 0,'S': 0,'Z': 0,'SH': 0,'ZH': 0,'HH': 0\n",
    "}\n",
    "\n",
    "def tag_phones(word, phones):\n",
    "    remove_digits = lambda x: re.sub('\\d*', '', x)\n",
    "    if isinstance(phones, str):\n",
    "        phones = remove_digits(phones).split(' ')\n",
    "    else:\n",
    "        phones = [remove_digits(p) for p in phones]\n",
    "    syls = []\n",
    "    tagged_phones = []\n",
    "    vowels = set(arp_to_ipa_vowels.keys())\n",
    "    hit_first_vowel = False\n",
    "    onset_buffer = []\n",
    "    skip = 0\n",
    "    for i, p in enumerate(phones):\n",
    "        if skip:\n",
    "            skip -= 1\n",
    "            continue\n",
    "        # runs potentially once\n",
    "        if p not in vowels and not hit_first_vowel:\n",
    "            tagged_phones.append((p, 'onset'))\n",
    "            continue\n",
    "        hit_first_vowel = True\n",
    "        if tagged_phones and p == tagged_phones[-1][0]:\n",
    "            continue\n",
    "        tagged_phones.append((p,'nucleus'))\n",
    "        remaining = phones[i+1:]\n",
    "        # if the rest of the word has vowels\n",
    "        remaining_vowels = set(remaining) & vowels\n",
    "        if not remaining_vowels:\n",
    "            tagged_phones += [(p, 'coda') for p in remaining]\n",
    "            break\n",
    "        # if there are vowels left\n",
    "        if not onset_buffer:\n",
    "            if not remaining:\n",
    "                continue\n",
    "            for x in remaining:\n",
    "                if x in vowels:\n",
    "                    break\n",
    "                else:\n",
    "                    onset_buffer.append(x)\n",
    "        while not legal(onset_buffer):\n",
    "            coda = onset_buffer.pop(0)\n",
    "            tagged_phones.append((coda, 'coda'))\n",
    "            skip += 1\n",
    "        skip += len(onset_buffer)\n",
    "        tagged_phones += [(p, 'onset') for p in onset_buffer]\n",
    "        onset_buffer = []\n",
    "    return tagged_phones\n",
    "\n",
    "def legal(onset):\n",
    "    if len(onset) == 1:\n",
    "        return True\n",
    "    scaled = lambda x: arp_sonority_scale.get(onset[x], 0)\n",
    "    diffs = []\n",
    "    for i, o in enumerate(onset):\n",
    "        if i < len(onset) - 1:\n",
    "            if abs(scaled(i) - scaled(i+1)) < 2:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def syls(tagged_phones):\n",
    "    syls = []\n",
    "    syl = []\n",
    "    for i, (phone, kind) in enumerate(tagged_phones):\n",
    "        syl.append(phone)\n",
    "        if i < len(tagged_phones) - 1:\n",
    "            next_kind = tagged_phones[i+1][1]\n",
    "            nuclei_break = [kind, next_kind] == ['nucleus'] * 2\n",
    "            onset_break = (next_kind == 'onset' and kind != 'onset')\n",
    "            if nuclei_break or onset_break:\n",
    "                syls.append(syl)\n",
    "                syl = []\n",
    "        else:\n",
    "            syls.append(syl)\n",
    "    return syls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pronouncing\n",
    "\n",
    "def match(graphemes, phonemes):\n",
    "    found = []\n",
    "    for i, line in enumerate(graphemes):\n",
    "        ## Build rolling window of 2-3 lines\n",
    "        # for the first line we compare it to the next line\n",
    "        if i == 0:\n",
    "            i_left, i_right = 0, 2\n",
    "        # for the last line we compare it to the previous\n",
    "        elif i == len(graphemes) - 1:\n",
    "            i_left, i_right = -2, -1\n",
    "        # for all other lines we compare to the previous\n",
    "        # and the next line\n",
    "        else:\n",
    "            i_left, i_right = i-1, i+2\n",
    "        ## Process phone groups before matching\n",
    "        filtered_lines = []\n",
    "        bank = defaultdict(int)\n",
    "        for phone_group in phonemes[i_left:i_right]:\n",
    "            # grab rhyming section of word (basic match)\n",
    "            rp = pronouncing.rhyming_part\n",
    "            rhyming_phones = [rp(word) for word in phone_group]\n",
    "            # remove middle constonants which don't have\n",
    "            # much to do with loose rhyming\n",
    "            nix_const = lambda x: re.sub('( \\w |\\d|[A-Z]{1,2} )+', ' ', x).strip().replace('  ', ' ')\n",
    "            filtered = list(map(nix_const, rhyming_phones))\n",
    "            filtered_lines.append(filtered)\n",
    "            # add filtered rhyming parts to common bank \n",
    "            # for current rolling window state\n",
    "            for f in filtered:\n",
    "                bank[f] += 1 \n",
    "        # match\n",
    "        found_rhymes = []\n",
    "        for phone_group in filtered_lines:\n",
    "            # positive match if rhyming phonemes in bank\n",
    "            # and also not single vowel\n",
    "            match = lambda x: bank[x] > 1 and ' ' in x\n",
    "            # create bitmap for words to determine if they rhyme\n",
    "            found_rhymes.append([match(w) for w in phone_group])\n",
    "        # if we're on the first line, or the line only has one word\n",
    "        if i == 0 or len(line) == 1:\n",
    "            found.append(found_rhymes[0])\n",
    "        else:            \n",
    "            found.append(found_rhymes[1])\n",
    "    finished = [list(zip(found[i], graphemes[i])) for i in range(len(found))]\n",
    "    return finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/hank/anaconda3/lib/python3.6/site-packages/g2p_en/logdir/model_epoch_14_gs_27956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[(False, 'Uh'),\n",
       "  (False, 'uh'),\n",
       "  (False, 'uh'),\n",
       "  (False, 'uh'),\n",
       "  (False, 'uh'),\n",
       "  (False, 'uh')],\n",
       " [(False, 'Uh'), (False, 'uh'), (False, 'uh'), (False, 'uh'), (False, 'uh')],\n",
       " [(False, 'Uh'),\n",
       "  (False, 'uh'),\n",
       "  (False, 'uh'),\n",
       "  (False, 'uh'),\n",
       "  (False, 'uh'),\n",
       "  (False, 'uh')],\n",
       " [(False, 'Uh'), (False, 'uh'), (False, 'uh'), (False, 'uh'), (False, 'ahhh')],\n",
       " [(True, 'Get'), (False, 'the'), (True, 'fuck'), (True, 'up')],\n",
       " [(False, 'Simon'),\n",
       "  (False, 'says'),\n",
       "  (True, 'Get'),\n",
       "  (False, 'the'),\n",
       "  (True, 'fuck'),\n",
       "  (True, 'up')],\n",
       " [(False, 'Throw'),\n",
       "  (False, 'your'),\n",
       "  (False, 'hands'),\n",
       "  (False, 'in'),\n",
       "  (False, 'the')],\n",
       " [(False, 'Queens'),\n",
       "  (False, 'is'),\n",
       "  (False, 'in'),\n",
       "  (False, 'the'),\n",
       "  (False, 'back'),\n",
       "  (False, 'sipping'),\n",
       "  (False, 'gnac'),\n",
       "  (False, \"y'all\"),\n",
       "  (False, \"what's\")],\n",
       " [(False, 'Girls'),\n",
       "  (True, 'rub'),\n",
       "  (True, 'on'),\n",
       "  (True, 'your'),\n",
       "  (True, 'titties')],\n",
       " [(False, 'Yeah'),\n",
       "  (False, 'I'),\n",
       "  (False, 'said'),\n",
       "  (False, 'it'),\n",
       "  (True, 'rub'),\n",
       "  (True, 'on'),\n",
       "  (True, 'your'),\n",
       "  (True, 'titties')],\n",
       " [(False, 'New'),\n",
       "  (False, 'York'),\n",
       "  (True, 'City'),\n",
       "  (True, 'gritty'),\n",
       "  (True, 'committee'),\n",
       "  (True, 'pity'),\n",
       "  (False, 'the'),\n",
       "  (False, 'fool')],\n",
       " [(True, 'That'),\n",
       "  (True, 'act'),\n",
       "  (False, 'shitty'),\n",
       "  (False, 'in'),\n",
       "  (False, 'the'),\n",
       "  (False, 'midst'),\n",
       "  (False, 'of'),\n",
       "  (False, 'the'),\n",
       "  (False, 'calm'),\n",
       "  (True, 'the')],\n",
       " [(False, \"Y'all\"), (False, 'know'), (False, 'the'), (False, 'name')],\n",
       " [(False, 'Pharoahe'),\n",
       "  (False, 'fuckin'),\n",
       "  (False, 'Monch'),\n",
       "  (False, \"ain't\"),\n",
       "  (False, 'a'),\n",
       "  (False, 'damn'),\n",
       "  (False, 'thing'),\n",
       "  (False, 'changed')],\n",
       " [(False, 'You'),\n",
       "  (False, 'all'),\n",
       "  (False, 'up'),\n",
       "  (False, 'in'),\n",
       "  (False, 'ya'),\n",
       "  (False, 'Range'),\n",
       "  (False, 'and'),\n",
       "  (False, 'shit')],\n",
       " [(False, 'Strayed'),\n",
       "  (False, 'from'),\n",
       "  (False, 'your'),\n",
       "  (False, 'original'),\n",
       "  (False, 'plan'),\n",
       "  (False, 'you'),\n",
       "  (True, 'deviated')],\n",
       " [(False, 'I'),\n",
       "  (True, 'alleviated'),\n",
       "  (False, 'the'),\n",
       "  (False, 'pain'),\n",
       "  (False, 'with'),\n",
       "  (False, 'long'),\n",
       "  (False, 'term')],\n",
       " [(False, 'Took'),\n",
       "  (False, 'my'),\n",
       "  (True, 'underground'),\n",
       "  (False, 'loot'),\n",
       "  (False, 'without'),\n",
       "  (False, 'the'),\n",
       "  (True, 'gold')],\n",
       " [(False, 'You'),\n",
       "  (True, 'sold'),\n",
       "  (False, 'platinum'),\n",
       "  (True, 'round'),\n",
       "  (False, 'the'),\n",
       "  (False, 'world'),\n",
       "  (False, 'I'),\n",
       "  (True, 'sold'),\n",
       "  (True, 'wood'),\n",
       "  (False, 'in'),\n",
       "  (True, 'the')],\n",
       " [(False, 'But'),\n",
       "  (False, 'when'),\n",
       "  (True, \"I'm\"),\n",
       "  (False, 'in'),\n",
       "  (False, 'the'),\n",
       "  (False, 'street'),\n",
       "  (False, 'and'),\n",
       "  (False, 'shit'),\n",
       "  (False, \"it's\"),\n",
       "  (True, 'all')],\n",
       " [(True, \"I'm\"),\n",
       "  (False, 'soon'),\n",
       "  (False, 'to'),\n",
       "  (False, 'motivate'),\n",
       "  (False, 'a'),\n",
       "  (True, 'room'),\n",
       "  (False, 'control'),\n",
       "  (False, 'the'),\n",
       "  (False, 'game'),\n",
       "  (True, 'like'),\n",
       "  (True, 'Tomb'),\n",
       "  (True, 'Raider')],\n",
       " [(True, 'Rock'),\n",
       "  (True, 'clock'),\n",
       "  (False, 'dollars'),\n",
       "  (False, 'flip'),\n",
       "  (False, 'tips'),\n",
       "  (True, 'like'),\n",
       "  (False, 'a'),\n",
       "  (True, 'waiter')],\n",
       " [(True, 'Block'),\n",
       "  (False, 'shots'),\n",
       "  (False, \"style's\"),\n",
       "  (True, 'greater'),\n",
       "  (False, 'let'),\n",
       "  (False, 'my'),\n",
       "  (False, 'lyrics'),\n",
       "  (True, 'anoint')],\n",
       " [(False, 'If'),\n",
       "  (False, 'you'),\n",
       "  (False, 'holding'),\n",
       "  (True, 'up'),\n",
       "  (False, 'the'),\n",
       "  (False, 'wall'),\n",
       "  (False, 'then'),\n",
       "  (False, 'you'),\n",
       "  (False, 'missin'),\n",
       "  (True, 'the')],\n",
       " [(True, 'Get'), (False, 'the'), (True, 'fuck'), (True, 'up')],\n",
       " [(False, 'Simon'),\n",
       "  (False, 'says'),\n",
       "  (True, 'Get'),\n",
       "  (False, 'the'),\n",
       "  (True, 'fuck'),\n",
       "  (True, 'up')],\n",
       " [(False, 'Put'),\n",
       "  (False, 'your'),\n",
       "  (False, 'hands'),\n",
       "  (False, 'to'),\n",
       "  (False, 'the'),\n",
       "  (False, 'sky')],\n",
       " [(False, 'Brooklyn'),\n",
       "  (False, 'in'),\n",
       "  (False, 'the'),\n",
       "  (False, 'back'),\n",
       "  (False, 'shooting'),\n",
       "  (False, 'craps'),\n",
       "  (False, 'now'),\n",
       "  (False, \"what's\")],\n",
       " [(True, 'Girlies'),\n",
       "  (True, 'rub'),\n",
       "  (True, 'on'),\n",
       "  (True, 'your'),\n",
       "  (True, 'titties')],\n",
       " [(False, 'Yeah'),\n",
       "  (False, 'fuck'),\n",
       "  (False, 'it'),\n",
       "  (False, 'I'),\n",
       "  (False, 'said'),\n",
       "  (True, 'rub'),\n",
       "  (True, 'on'),\n",
       "  (True, 'your'),\n",
       "  (True, 'titties')],\n",
       " [(False, 'New'),\n",
       "  (False, 'York'),\n",
       "  (True, 'City'),\n",
       "  (True, 'gritty'),\n",
       "  (True, 'committee'),\n",
       "  (True, 'pity'),\n",
       "  (False, 'the'),\n",
       "  (False, 'fool')],\n",
       " [(True, 'That'),\n",
       "  (True, 'act'),\n",
       "  (False, 'shitty'),\n",
       "  (False, 'in'),\n",
       "  (False, 'the'),\n",
       "  (False, 'midst'),\n",
       "  (False, 'of'),\n",
       "  (False, 'the'),\n",
       "  (False, 'calm'),\n",
       "  (True, 'the')],\n",
       " [(False, 'Yo'),\n",
       "  (False, 'where'),\n",
       "  (False, 'you'),\n",
       "  (True, 'at'),\n",
       "  (False, 'Uptown'),\n",
       "  (False, 'let'),\n",
       "  (False, 'me'),\n",
       "  (False, 'see'),\n",
       "  (False, 'em')],\n",
       " [(False, 'Notorious'),\n",
       "  (False, 'for'),\n",
       "  (False, 'the'),\n",
       "  (False, 'six'),\n",
       "  (False, 'fives'),\n",
       "  (False, 'and'),\n",
       "  (False, 'the'),\n",
       "  (False, 'BMs')],\n",
       " [(False, 'Heads'),\n",
       "  (False, 'give'),\n",
       "  (False, 'you'),\n",
       "  (False, 'beef'),\n",
       "  (False, 'you'),\n",
       "  (False, 'put'),\n",
       "  (False, 'em'),\n",
       "  (False, 'in'),\n",
       "  (False, 'the')],\n",
       " [(False, 'And'),\n",
       "  (False, 'shit'),\n",
       "  (False, \"don't\"),\n",
       "  (False, 'start'),\n",
       "  (False, 'pumping'),\n",
       "  (False, 'til'),\n",
       "  (False, 'after'),\n",
       "  (False, '12pm')],\n",
       " [(False, 'Uh'),\n",
       "  (False, 'ignorant'),\n",
       "  (False, 'minds'),\n",
       "  (False, 'I'),\n",
       "  (False, 'free'),\n",
       "  (False, 'em')],\n",
       " [(False, 'If'),\n",
       "  (False, 'you'),\n",
       "  (False, 'tired'),\n",
       "  (False, 'of'),\n",
       "  (False, 'the'),\n",
       "  (False, 'same'),\n",
       "  (False, 'old'),\n",
       "  (False, 'everyday'),\n",
       "  (False, 'you'),\n",
       "  (False, 'will'),\n",
       "  (False, 'agree')],\n",
       " [(False, \"I'm\"),\n",
       "  (False, 'the'),\n",
       "  (False, 'most'),\n",
       "  (True, 'obligated'),\n",
       "  (False, 'hard'),\n",
       "  (False, 'and'),\n",
       "  (True, 'R'),\n",
       "  (False, 'rated')],\n",
       " [(True, 'Slated'),\n",
       "  (False, 'to'),\n",
       "  (False, 'be'),\n",
       "  (False, 'the'),\n",
       "  (False, 'best'),\n",
       "  (False, 'I'),\n",
       "  (False, 'must'),\n",
       "  (True, 'confess'),\n",
       "  (False, 'the'),\n",
       "  (True, 'star'),\n",
       "  (False, 'made'),\n",
       "  (False, 'it')],\n",
       " [(False, 'Some'),\n",
       "  (False, 'might'),\n",
       "  (False, 'even'),\n",
       "  (False, 'say'),\n",
       "  (False, 'this'),\n",
       "  (False, 'song'),\n",
       "  (False, 'is'),\n",
       "  (False, 'sexist'),\n",
       "  (True, 'es')],\n",
       " [(False, 'Cause'),\n",
       "  (False, 'I'),\n",
       "  (False, 'asked'),\n",
       "  (False, 'the'),\n",
       "  (False, 'girls'),\n",
       "  (False, 'to'),\n",
       "  (False, 'rub'),\n",
       "  (False, 'on'),\n",
       "  (False, 'their'),\n",
       "  (False, 'breast'),\n",
       "  (False, 'eses')],\n",
       " [(False, 'Whether'),\n",
       "  (False, \"you're\"),\n",
       "  (False, 'riding'),\n",
       "  (False, 'the'),\n",
       "  (True, 'train'),\n",
       "  (False, 'or'),\n",
       "  (False, 'a'),\n",
       "  (False, 'Lexus')],\n",
       " [(False, 'This'),\n",
       "  (False, 'is'),\n",
       "  (True, 'for'),\n",
       "  (False, 'either'),\n",
       "  (True, 'or'),\n",
       "  (False, 'Rollies'),\n",
       "  (True, 'or'),\n",
       "  (False, 'Timex'),\n",
       "  (False, 'eses')],\n",
       " [(False, 'Wicked'), (False, 'like')],\n",
       " [(False, 'Exorcist')],\n",
       " [(False, 'this'), (False, 'is'), (False, 'the'), (True, 'joint')],\n",
       " [(False, 'You'),\n",
       "  (False, 'holding'),\n",
       "  (True, 'up'),\n",
       "  (False, 'the'),\n",
       "  (False, 'wall'),\n",
       "  (False, 'then'),\n",
       "  (False, 'you'),\n",
       "  (False, 'missing'),\n",
       "  (False, 'the'),\n",
       "  (True, 'point')],\n",
       " [(True, 'Get'), (False, 'the'), (True, 'fuck'), (True, 'up')],\n",
       " [(False, 'Simon'),\n",
       "  (False, 'says'),\n",
       "  (True, 'Get'),\n",
       "  (False, 'the'),\n",
       "  (True, 'fuck'),\n",
       "  (True, 'up')],\n",
       " [(False, 'Throw'),\n",
       "  (False, 'your'),\n",
       "  (False, 'hands'),\n",
       "  (False, 'in'),\n",
       "  (False, 'the')],\n",
       " [(False, 'The'),\n",
       "  (False, 'Bronx'),\n",
       "  (False, 'is'),\n",
       "  (False, 'in'),\n",
       "  (False, 'the'),\n",
       "  (False, 'back'),\n",
       "  (False, 'shooting'),\n",
       "  (False, 'craps'),\n",
       "  (False, 'now'),\n",
       "  (False, \"what's\")],\n",
       " [(False, 'Girls'),\n",
       "  (True, 'rub'),\n",
       "  (True, 'on'),\n",
       "  (True, 'your'),\n",
       "  (True, 'titties')],\n",
       " [(False, 'I'),\n",
       "  (False, 'said'),\n",
       "  (True, 'rub'),\n",
       "  (True, 'on'),\n",
       "  (True, 'your'),\n",
       "  (True, 'titties')],\n",
       " [(False, 'New'),\n",
       "  (False, 'York'),\n",
       "  (True, 'City'),\n",
       "  (True, 'gritty'),\n",
       "  (True, 'committee'),\n",
       "  (True, 'pity'),\n",
       "  (False, 'the'),\n",
       "  (False, 'fool')],\n",
       " [(True, 'That'),\n",
       "  (True, 'act'),\n",
       "  (False, 'shitty'),\n",
       "  (False, 'in'),\n",
       "  (False, 'the'),\n",
       "  (False, 'midst'),\n",
       "  (False, 'of'),\n",
       "  (False, 'the'),\n",
       "  (False, 'calm'),\n",
       "  (True, 'the')],\n",
       " [(False, 'New'), (False, 'Jeru')],\n",
       " [(False, 'Shaolin')],\n",
       " [(False, 'Long'), (False, 'Isle')],\n",
       " [(False, 'Worldwide')]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned = clean_headers(lyric)\n",
    "processed = get_phones(cleaned)\n",
    "matched = match(cleaned, processed)\n",
    "matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br>Uh uh uh uh uh uh </br><br>Uh uh uh uh uh </br><br>Uh uh uh uh uh uh </br><br>Uh uh uh uh ahhh </br><br><b>Get </b>the <b>fuck </b><b>up </b></br><br>Simon says <b>Get </b>the <b>fuck </b><b>up </b></br><br>Throw your hands in the </br><br>Queens is in the back sipping gnac y'all what's </br><br>Girls <b>rub </b><b>on </b><b>your </b><b>titties </b></br><br>Yeah I said it <b>rub </b><b>on </b><b>your </b><b>titties </b></br><br>New York <b>City </b><b>gritty </b><b>committee </b><b>pity </b>the fool </br><br><b>That </b><b>act </b>shitty in the midst of the calm the </br><br>Y'all know the name </br><br>Pharoahe fuckin Monch ain't a damn thing changed </br><br>You all up in ya Range and shit </br><br>Strayed from your original plan you <b>deviated </b></br><br>I <b>alleviated </b>the pain with long term </br><br>Took my <b>underground </b>loot without the <b>gold </b></br><br>You <b>sold </b>platinum <b>round </b>the world I <b>sold </b><b>wood </b>in the </br><br>But when <b>I'm </b>in the street and shit it's all </br><br><b>I'm </b>soon to motivate a <b>room </b>control the game <b>like </b><b>Tomb </b><b>Raider </b></br><br><b>Rock </b><b>clock </b>dollars flip tips <b>like </b>a <b>waiter </b></br><br><b>Block </b>shots style's <b>greater </b>let my lyrics <b>anoint </b></br><br>If you holding <b>up </b>the wall then you missin the </br><br><b>Get </b>the <b>fuck </b><b>up </b></br><br>Simon says <b>Get </b>the <b>fuck </b><b>up </b></br><br>Put your hands to the sky </br><br>Brooklyn in the back shooting craps now what's </br><br><b>Girlies </b><b>rub </b><b>on </b><b>your </b><b>titties </b></br><br>Yeah fuck it I said <b>rub </b><b>on </b><b>your </b><b>titties </b></br><br>New York <b>City </b><b>gritty </b><b>committee </b><b>pity </b>the fool </br><br><b>That </b><b>act </b>shitty in the midst of the calm the </br><br>Yo where you <b>at </b>Uptown let me see em </br><br>Notorious for the six fives and the BMs </br><br>Heads give you beef you put em in the </br><br>And shit don't start pumping til after 12pm </br><br>Uh ignorant minds I free em </br><br>If you tired of the same old everyday you will agree </br><br>I'm the most <b>obligated </b>hard and <b>R </b>rated </br><br><b>Slated </b>to be the best I must <b>confess </b>the <b>star </b>made it </br><br>Some might even say this song is sexist <b>es </b></br><br>Cause I asked the girls to rub on their breast eses </br><br>Whether you're riding the <b>train </b>or a Lexus </br><br>This is <b>for </b>either <b>or </b>Rollies <b>or </b>Timex eses </br><br>Wicked like </br><br>Exorcist </br><br>this is the <b>joint </b></br><br>You holding <b>up </b>the wall then you missing the <b>point </b></br><br><b>Get </b>the <b>fuck </b><b>up </b></br><br>Simon says <b>Get </b>the <b>fuck </b><b>up </b></br><br>Throw your hands in the </br><br>The Bronx is in the back shooting craps now what's </br><br>Girls <b>rub </b><b>on </b><b>your </b><b>titties </b></br><br>I said <b>rub </b><b>on </b><b>your </b><b>titties </b></br><br>New York <b>City </b><b>gritty </b><b>committee </b><b>pity </b>the fool </br><br><b>That </b><b>act </b>shitty in the midst of the calm the </br><br>New Jeru </br><br>Shaolin </br><br>Long Isle </br><br>Worldwide </br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "buff = ''\n",
    "dont_match = set([\n",
    "    \"the\",\"be\",\"to\",\"of\",\"and\",\"a\",\"in\",\"that\",\"have\",\n",
    "    \"I\",\"it\",\"for\",\"not\",\"on\",\"with\",\"he\",\"as\",\"you\",\n",
    "    \"do\",\"at\",\"this\",\"but\",\"his\",\"by\",\"from\",\"they\",\n",
    "    \"we\",\"say\",\"her\",\"she\",\"or\",\"an\",\"will\",\"my\",\"one\",\n",
    "    \"all\",\"world\",\"there\",\"their\",\"what\",\"so\",\"who\",\n",
    "    \"if\",\"them\",\"yeah\"\n",
    "])\n",
    "for line in matched:\n",
    "    buff += '<br>'\n",
    "    for i, (rhymes, word) in enumerate(line):\n",
    "        if rhymes and (word not in dont_match or i < len(line) -1):\n",
    "            buff += '<b>{} </b>'.format(word)\n",
    "        else:\n",
    "            buff += word + ' '\n",
    "    buff += '</br>'\n",
    "display(HTML(buff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/hank/anaconda3/lib/python3.6/site-packages/g2p_en/logdir/model_epoch_14_gs_27956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'N OW0 T AO1 R IY0 AH0 S'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shitty = get_phones([[\"Notorious\", 'witty', 'pity']])[0][0]\n",
    "shitty\n",
    "# re.sub('( \\w |\\d|[A-Z]{1,2} )+', ' ', shitty).strip().replace('  ', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# until current phoneme is a vowel\n",
    "#     label current phoneme as an onset\n",
    "# end loop\n",
    "# until all phonemes have been labeled\n",
    "#     label current phoneme as a nucleus\n",
    "#     if there are no more vowels in the word\n",
    "#         label all remaining consonants as codas\n",
    "#     else\n",
    "#         onset := all consonants before next vowel\n",
    "#         coda := empty\n",
    "#         until onset is legal\n",
    "#             coda := coda plus first phoneme of onset\n",
    "#             onset := onset less first phoneme\n",
    "#         end loop\n",
    "#     end if\n",
    "# end loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/hank/anaconda3/lib/python3.6/site-packages/g2p_en/logdir/model_epoch_14_gs_27956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/hank/anaconda3/lib/python3.6/site-packages/g2p_en/logdir/model_epoch_14_gs_27956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('HH', 'onset'),\n",
       " ('AA', 'nucleus'),\n",
       " ('S', 'coda'),\n",
       " ('P', 'onset'),\n",
       " ('IH', 'nucleus'),\n",
       " ('T', 'onset'),\n",
       " ('AH', 'nucleus'),\n",
       " ('L', 'coda')]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'hospital'\n",
    "phones = get_phones([[word]])[0][0]\n",
    "tagged_phones = tag_phones(word, phones)\n",
    "tagged_phones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['HH', 'AA', 'S'], ['P', 'IH'], ['T', 'AH', 'L']]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syls(tagged_phones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from syllabifyARPA import syllabifyARPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     HH AA1\n",
       "1    S P IH2\n",
       "2    T AH0 L\n",
       "dtype: object"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syllabifyARPA(phones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/hank/anaconda3/lib/python3.6/site-packages/g2p_en/logdir/model_epoch_14_gs_27956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/hank/anaconda3/lib/python3.6/site-packages/g2p_en/logdir/model_epoch_14_gs_27956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'IH2 NG K AA1 N S P IH0 K W AH0 S'"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_phones([[word]])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IH0 NG K AA1 N S P IH0 K Y UW AH0 S'"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(['IH0', 'NG', 'K', 'AA1', 'N', 'S', 'P', 'IH0', 'K', 'Y', 'UW', 'AH0', 'S'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
